{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils import (\n",
    "    read_single_problem_from_path_as_adjacency,\n",
    "    check_validity_for_adjacency,\n",
    "    max_best_iterations_without_improve_parameter\n",
    ")\n",
    "from constants import (\n",
    "    BASE_INSTANCES_FILES,\n",
    "    OTHER_INSTANCES_FILES,\n",
    "    OTHER_INSTANCES_BEST_KNOWN,\n",
    "    BASE_INSTANCES_BEST_KNOWN,\n",
    "    ALL_BEST_KNOWN,\n",
    ")\n",
    "from heuristics import descending_degree_glutonous_heuristic\n",
    "from meta_heuristics import (\n",
    "    base_vns_meta_heuristic,\n",
    "    enhanced_base_vns_meta_heuristic,\n",
    "    exploring_base_vns_meta_heuristic,\n",
    ")\n",
    "\n",
    "# Constants\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "# Instances pathes\n",
    "INSTANCES_DIR = ROOT_DIR / \"instances\"\n",
    "BASE_INSTANCES_DIR = INSTANCES_DIR / \"project_instances\"\n",
    "OTHER_INSTANCES_DIR = INSTANCES_DIR / \"other_instances\"\n",
    "ALL_INSTANCES_PATH_TUPLES = [\n",
    "    (instance, OTHER_INSTANCES_DIR / instance) for instance in OTHER_INSTANCES_FILES\n",
    "] + [(instance, BASE_INSTANCES_DIR / instance) for instance in BASE_INSTANCES_FILES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the clique valid ?  True\n",
      "Is the clique different ? False\n"
     ]
    }
   ],
   "source": [
    "# Testing vns base heuristic on a graph\n",
    "_, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "    instance_path=BASE_INSTANCES_DIR / \"brock200_2.col\"\n",
    ")\n",
    "starting_clique = descending_degree_glutonous_heuristic(graph=graph, degrees=degrees)\n",
    "clique, _, _, _ = base_vns_meta_heuristic(\n",
    "    starting_clique=starting_clique, graph=graph, degrees=degrees, max_time=5\n",
    ")\n",
    "print(\"Is the clique valid ? \", check_validity_for_adjacency(graph, clique))\n",
    "print(\"Is the clique different ?\", all(clique == starting_clique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on all graphs and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"max_k\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "\n",
    "# Running\n",
    "for instance in BASE_INSTANCES_FILES[:3]:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=BASE_INSTANCES_DIR / instance\n",
    "    )\n",
    "    for k in range(2, 10):\n",
    "        starting_clique = descending_degree_glutonous_heuristic(\n",
    "            graph=graph, degrees=degrees\n",
    "        )\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=10,\n",
    "            biggest_neighbourhood_size=k,\n",
    "        )\n",
    "\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            k,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            BASE_INSTANCES_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / BASE_INSTANCES_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_base_results_for_base_instances_2.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on all graphs and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"max_k\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    for k in range(2, 20, 3):\n",
    "        starting_clique = descending_degree_glutonous_heuristic(\n",
    "            graph=graph, degrees=degrees\n",
    "        )\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=20,\n",
    "            biggest_neighbourhood_size=k,\n",
    "        )\n",
    "\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            k,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_base_results_for_other_instances_2.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on single graph and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"max_k\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "\n",
    "# Running\n",
    "for instance in [\"brock800_4.txt\"]:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    for k in range(2, 20):\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=8,\n",
    "            biggest_neighbourhood_size=k,\n",
    "        )\n",
    "\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            k,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"brock800_4_tests.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing our two starting metas\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 60\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    # Base heuristic\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"base\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "    # Heuristic with restarts\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = enhanced_base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        max_iterations_without_improvement=5,\n",
    "        penalization=3,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"restart\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_versus_enhanced_penalization_3.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our base vns on all graphs.\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance, path in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    # Base heuristic\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"base\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_base_all_instances_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our exploring vns on all graphs.\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "max_iterations_without_improve = 5\n",
    "# Running\n",
    "for instance, path in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = exploring_base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "        max_iterations_without_improve=max_iterations_without_improve,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"exploring\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_exploring_all_instances_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Testing exploring on single instance but with different max iterations\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"iter_no_improv\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance, path in [(\"C500.9.txt\", OTHER_INSTANCES_DIR / \"C500.9.txt\")]:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    for max_iterations_without_improve in range(2, 12):\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = exploring_base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=max_time,\n",
    "            biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "            max_iterations_without_improve=max_iterations_without_improve,\n",
    "        )\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            \"exploring\",\n",
    "            max_iterations_without_improve,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            ALL_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "display_dataframe.to_csv(\"vns_exploring_depending_max_iter_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 47\u001b[0m\n\u001b[0;32m     28\u001b[0m starting_clique \u001b[39m=\u001b[39m descending_degree_glutonous_heuristic(\n\u001b[0;32m     29\u001b[0m     graph\u001b[39m=\u001b[39mgraph, degrees\u001b[39m=\u001b[39mdegrees\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m runner \u001b[39m=\u001b[39m ExploringMetaHeuristicRunner(\n\u001b[0;32m     32\u001b[0m     graph\u001b[39m=\u001b[39mgraph,\n\u001b[0;32m     33\u001b[0m     degrees\u001b[39m=\u001b[39mdegrees,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     max_exploring_iterations_without_improve\u001b[39m=\u001b[39mmax_iterations_without_improve,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     42\u001b[0m (\n\u001b[0;32m     43\u001b[0m     clique,\n\u001b[0;32m     44\u001b[0m     time_best_found,\n\u001b[0;32m     45\u001b[0m     iteration_of_best,\n\u001b[0;32m     46\u001b[0m     number_of_iterations,\n\u001b[1;32m---> 47\u001b[0m ) \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39;49mexploring_base_vns_meta_heuristic()\n\u001b[0;32m     48\u001b[0m \u001b[39massert\u001b[39;00m(check_validity_for_adjacency(graph, clique))\n\u001b[0;32m     49\u001b[0m \u001b[39m# Adding to display\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\GitHub\\projet_MH\\meta_heuristics\\exploring_descending_base_vns.py:233\u001b[0m, in \u001b[0;36mExploringMetaHeuristicRunner.exploring_base_vns_meta_heuristic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_biggest_neighbourhood_size \u001b[39m=\u001b[39m (\n\u001b[0;32m    227\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_current_biggest_neighbourhood_size(\n\u001b[0;32m    228\u001b[0m                 size_of_clique\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_clique)\n\u001b[0;32m    229\u001b[0m             )\n\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    232\u001b[0m     \u001b[39m# Exploring part\u001b[39;00m\n\u001b[1;32m--> 233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplore_from_current_clique()\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_clique,\n\u001b[0;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime_best_found,\n\u001b[0;32m    238\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miteration_best_clique,\n\u001b[0;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_of_iterations,\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\GitHub\\projet_MH\\meta_heuristics\\exploring_descending_base_vns.py:164\u001b[0m, in \u001b[0;36mExploringMetaHeuristicRunner.explore_from_current_clique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m     new_clique[node] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[39m# Search new best clique greedily from there.\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m descending_random_from_clique(\n\u001b[0;32m    165\u001b[0m     clique\u001b[39m=\u001b[39;49mnew_clique, graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph, degrees\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegrees\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m \u001b[39m# See if the new result is better\u001b[39;00m\n\u001b[0;32m    168\u001b[0m new_size \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(new_clique)\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\GitHub\\projet_MH\\heuristics\\descending_random.py:27\u001b[0m, in \u001b[0;36mdescending_random_from_clique\u001b[1;34m(clique, graph, degrees)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m degrees[candidate_node] \u001b[39m<\u001b[39m clique_size:\n\u001b[0;32m     25\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m---> 27\u001b[0m     np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49mtake(graph[candidate_node], indices\u001b[39m=\u001b[39;49mclique_nodes)) \u001b[39m==\u001b[39m clique_size\n\u001b[0;32m     28\u001b[0m ):\n\u001b[0;32m     29\u001b[0m     clique_nodes\u001b[39m.\u001b[39mappend(candidate_node)\n\u001b[0;32m     30\u001b[0m     clique[candidate_node] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\GitHub\\projet_MH\\lib\\site-packages\\numpy\\core\\fromnumeric.py:190\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(a, indices, axis, out, mode)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_take_dispatcher)\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtake\u001b[39m(a, indices, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m    Take elements from an array along an axis.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m           [5, 7]])\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mtake\u001b[39;49m\u001b[39m'\u001b[39;49m, indices, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, mode\u001b[39m=\u001b[39;49mmode)\n",
      "File \u001b[1;32mc:\\Users\\alexi\\Documents\\GitHub\\projet_MH\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  Results of our exploring runner on our instances.\n",
    "from meta_heuristics import ExploringMetaHeuristicRunner\n",
    "\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 120\n",
    "biggest_neighbourhood_size = 5\n",
    "max_best_iterations_without_improve = 5\n",
    "max_iterations_without_improve = 2 * max_best_iterations_without_improve\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    runner = ExploringMetaHeuristicRunner(\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        starting_clique=starting_clique,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "        max_time=max_time,\n",
    "        # verbose=True,\n",
    "        max_best_iterations_without_improve=max_best_iterations_without_improve,\n",
    "        max_exploring_iterations_without_improve=max_iterations_without_improve,\n",
    "    )\n",
    "\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = runner.exploring_base_vns_meta_heuristic()\n",
    "    assert check_validity_for_adjacency(graph, clique)\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"expl v2\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_exploring_2_other_instances_120_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our exploring runner with taboos on our instances.\n",
    "from meta_heuristics import ExploringTaboosMetaHeuristicRunner\n",
    "from math import ceil, log\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "\n",
    "    # max_intensification_without_improve = max_best_iterations_without_improve_parameter(clique_size=np.sum(starting_clique))\n",
    "    # print(\"Instance\", instance, \"param\", max_intensification_without_improve)\n",
    "    max_intensification_without_improve = 10\n",
    "    max_exploring_iterations_without_improve = 3 * max_intensification_without_improve\n",
    "\n",
    "    max_taboos = min(10, ceil(np.sqrt(np.sum(starting_clique))))\n",
    "    runner = ExploringTaboosMetaHeuristicRunner(\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        starting_clique=starting_clique,\n",
    "        max_time=max_time,\n",
    "        # verbose=True,\n",
    "        max_intensification_without_improve=max_intensification_without_improve,\n",
    "        max_exploring_iterations_without_improve=max_exploring_iterations_without_improve,\n",
    "    )\n",
    "\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = runner.exploring_base_vns_meta_heuristic()\n",
    "    assert check_validity_for_adjacency(graph, clique)\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"expl taboo\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(f\"vns_exploring_taboo_smaller_intensification_{max_time}_sec.csv\", sep=\";\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('projet_MH': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "394d83e5b1ffce0d121f660ba29d6d2dfe8b3a88ed0a25224231f21a953d4a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
