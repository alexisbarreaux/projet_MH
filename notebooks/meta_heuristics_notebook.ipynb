{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from utils import (\n",
    "    read_single_problem_from_path_as_adjacency,\n",
    "    check_validity_for_adjacency,\n",
    "    max_best_iterations_without_improve_parameter\n",
    ")\n",
    "from constants import (\n",
    "    BASE_INSTANCES_FILES,\n",
    "    OTHER_INSTANCES_FILES,\n",
    "    OTHER_INSTANCES_BEST_KNOWN,\n",
    "    BASE_INSTANCES_BEST_KNOWN,\n",
    "    ALL_BEST_KNOWN,\n",
    ")\n",
    "from heuristics import descending_degree_glutonous_heuristic\n",
    "from meta_heuristics import (\n",
    "    base_vns_meta_heuristic,\n",
    "    enhanced_base_vns_meta_heuristic,\n",
    "    exploring_base_vns_meta_heuristic,\n",
    ")\n",
    "\n",
    "# Constants\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "# Instances pathes\n",
    "INSTANCES_DIR = ROOT_DIR / \"instances\"\n",
    "BASE_INSTANCES_DIR = INSTANCES_DIR / \"project_instances\"\n",
    "OTHER_INSTANCES_DIR = INSTANCES_DIR / \"other_instances\"\n",
    "ALL_INSTANCES_PATH_TUPLES = [\n",
    "    (instance, OTHER_INSTANCES_DIR / instance) for instance in OTHER_INSTANCES_FILES\n",
    "] + [(instance, BASE_INSTANCES_DIR / instance) for instance in BASE_INSTANCES_FILES]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the clique valid ?  True\n",
      "Is the clique different ? False\n"
     ]
    }
   ],
   "source": [
    "# Testing vns base heuristic on a graph\n",
    "_, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "    instance_path=BASE_INSTANCES_DIR / \"brock200_2.col\"\n",
    ")\n",
    "starting_clique = descending_degree_glutonous_heuristic(graph=graph, degrees=degrees)\n",
    "clique, _, _, _ = base_vns_meta_heuristic(\n",
    "    starting_clique=starting_clique, graph=graph, degrees=degrees, max_time=5\n",
    ")\n",
    "print(\"Is the clique valid ? \", check_validity_for_adjacency(graph, clique))\n",
    "print(\"Is the clique different ?\", all(clique == starting_clique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on all graphs and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 120\n",
    "# Running\n",
    "for (instance, path) in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=5,\n",
    "    )\n",
    "\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(f\"vns_base_all_instances_{max_time}_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on all graphs and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"max_k\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    for k in range(2, 20, 3):\n",
    "        starting_clique = descending_degree_glutonous_heuristic(\n",
    "            graph=graph, degrees=degrees\n",
    "        )\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=20,\n",
    "            biggest_neighbourhood_size=k,\n",
    "        )\n",
    "\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            k,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_base_results_for_other_instances_2.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on single graph and displaying results\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"max_k\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "\n",
    "# Running\n",
    "for instance in [\"brock800_4.txt\"]:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    for k in range(2, 20):\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=8,\n",
    "            biggest_neighbourhood_size=k,\n",
    "        )\n",
    "\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            k,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"brock800_4_tests.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing our two starting metas\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 60\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    # Base heuristic\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"base\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "    # Heuristic with restarts\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = enhanced_base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        max_iterations_without_improvement=5,\n",
    "        penalization=3,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"restart\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        OTHER_INSTANCES_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / OTHER_INSTANCES_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_versus_enhanced_penalization_3.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our base vns on all graphs.\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance, path in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    # Base heuristic\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"base\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_base_all_instances_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our exploring vns on all graphs.\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "max_iterations_without_improve = 5\n",
    "# Running\n",
    "for instance, path in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = exploring_base_vns_meta_heuristic(\n",
    "        starting_clique=starting_clique,\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        max_time=max_time,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "        max_iterations_without_improve=max_iterations_without_improve,\n",
    "    )\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"exploring\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(\"vns_exploring_all_instances_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Testing exploring on single instance but with different max iterations\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"iter_no_improv\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "biggest_neighbourhood_size = 5\n",
    "# Running\n",
    "for instance, path in [(\"C500.9.txt\", OTHER_INSTANCES_DIR / \"C500.9.txt\")]:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    for max_iterations_without_improve in range(2, 12):\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = exploring_base_vns_meta_heuristic(\n",
    "            starting_clique=starting_clique,\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            max_time=max_time,\n",
    "            biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "            max_iterations_without_improve=max_iterations_without_improve,\n",
    "        )\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            \"exploring\",\n",
    "            max_iterations_without_improve,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            ALL_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "display_dataframe.to_csv(\"vns_exploring_depending_max_iter_30_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Results of our exploring runner on our instances.\n",
    "from meta_heuristics import ExploringMetaHeuristicRunner\n",
    "\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 120\n",
    "biggest_neighbourhood_size = 5\n",
    "max_best_iterations_without_improve = 5\n",
    "max_iterations_without_improve = 2 * max_best_iterations_without_improve\n",
    "# Running\n",
    "for instance, path in ALL_INSTANCES_PATH_TUPLES:\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=path\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    runner = ExploringMetaHeuristicRunner(\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        starting_clique=starting_clique,\n",
    "        biggest_neighbourhood_size=biggest_neighbourhood_size,\n",
    "        max_time=max_time,\n",
    "        # verbose=True,\n",
    "        max_best_iterations_without_improve=max_best_iterations_without_improve,\n",
    "        max_exploring_iterations_without_improve=max_iterations_without_improve,\n",
    "    )\n",
    "\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = runner.meta_heuristic()\n",
    "    assert check_validity_for_adjacency(graph, clique)\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"expl v2\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(f\"vns_exploring_2_all_instances_{max_time}_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsjc500.9.col\n",
      "dsjc500.5.col\n",
      "dsjc500.1.col\n",
      "dsjc250.5.col\n",
      "dsjc1000.9.col\n",
      "dsjc1000.5.col\n",
      "dsjc1000.1.col\n",
      "p_hat700-1.txt\n",
      "p_hat1500-3.txt\n",
      "gen400_p0.9_75.txt\n",
      "C500.9.txt\n",
      "C2000.5.txt\n",
      "brock800_4.txt\n"
     ]
    }
   ],
   "source": [
    "#  Results of our exploring runner with taboos on our instances.\n",
    "from meta_heuristics import ExploringTaboosMetaHeuristicRunner\n",
    "from math import ceil, log\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 30\n",
    "\n",
    "# Running\n",
    "for instance in OTHER_INSTANCES_FILES[::-1]:\n",
    "    print(instance)\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=OTHER_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "\n",
    "    # max_intensification_without_improve = max_best_iterations_without_improve_parameter(clique_size=np.sum(starting_clique))\n",
    "    # print(\"Instance\", instance, \"param\", max_intensification_without_improve)\n",
    "    max_intensification_without_improve = 10\n",
    "    max_exploring_iterations_without_improve = 3 * max_intensification_without_improve\n",
    "\n",
    "    max_taboos = min(10, ceil(np.sqrt(np.sum(starting_clique))))\n",
    "    runner = ExploringTaboosMetaHeuristicRunner(\n",
    "        graph=graph,\n",
    "        degrees=degrees,\n",
    "        starting_clique=starting_clique,\n",
    "        max_time=max_time,\n",
    "        # verbose=True,\n",
    "        max_intensification_without_improve=max_intensification_without_improve,\n",
    "        max_exploring_iterations_without_improve=max_exploring_iterations_without_improve,\n",
    "    )\n",
    "\n",
    "    (\n",
    "        clique,\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ) = runner.meta_heuristic()\n",
    "    assert check_validity_for_adjacency(graph, clique)\n",
    "    # Adding to display\n",
    "    new_row = [\n",
    "        instance,\n",
    "        \"expl taboo\",\n",
    "        np.sum(starting_clique),\n",
    "        np.sum(clique),\n",
    "        ALL_BEST_KNOWN[instance],\n",
    "        \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "        \"{:.1%}\".format(\n",
    "            np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "        ),\n",
    "        time_best_found,\n",
    "        iteration_of_best,\n",
    "        number_of_iterations,\n",
    "    ]\n",
    "    display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(f\"vns_exploring_taboo_smaller_intensification_{max_time}_sec.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsjc125.1.col\n",
      "random-10.col\n",
      "random-100.col\n",
      "random-40.col\n",
      "random-70.col\n"
     ]
    }
   ],
   "source": [
    "#  Comparing three methods\n",
    "from meta_heuristics import ExploringMetaHeuristicRunner, ExploringTaboosMetaHeuristicRunner, ExploringTaboosRestartMetaHeuristicRunner\n",
    "from math import ceil, log\n",
    "\n",
    "# Display setup\n",
    "columns = [\n",
    "    \"instance\",\n",
    "    \"method\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"bound\",\n",
    "    \"gap\",\n",
    "    \"start/end diff\",\n",
    "    \"time of best\",\n",
    "    \"iteration_of_best\",\n",
    "    \"total_iterations\",\n",
    "]\n",
    "display_dataframe = pd.DataFrame({column: [] for column in columns})\n",
    "max_time = 240\n",
    "max_intensification_without_improve = 5\n",
    "max_exploring_iterations_without_improve = 3 * max_intensification_without_improve\n",
    "max_restarts_iterations_without_improve = max_intensification_without_improve\n",
    "# Running\n",
    "for instance in BASE_INSTANCES_FILES[1:]:\n",
    "    print(instance)\n",
    "    number_of_nodes, _, graph, degrees = read_single_problem_from_path_as_adjacency(\n",
    "        instance_path=BASE_INSTANCES_DIR / instance\n",
    "    )\n",
    "    starting_clique = descending_degree_glutonous_heuristic(\n",
    "        graph=graph, degrees=degrees\n",
    "    )\n",
    "    for runner_class, name in ((ExploringMetaHeuristicRunner, \"expl v2\"), (ExploringTaboosMetaHeuristicRunner, \"taboos\"), (ExploringTaboosRestartMetaHeuristicRunner, \"restart\")):\n",
    "    #for runner_class, name in ([(ExploringTaboosRestartMetaHeuristicRunner, \"restart\")]):\n",
    "\n",
    "\n",
    "        max_taboos = min(10, ceil(np.sqrt(np.sum(starting_clique))))\n",
    "        runner = runner_class(\n",
    "            graph=graph,\n",
    "            degrees=degrees,\n",
    "            starting_clique=starting_clique,\n",
    "            max_time=max_time,\n",
    "            max_intensification_without_improve=max_intensification_without_improve,\n",
    "            max_exploring_iterations_without_improve=max_exploring_iterations_without_improve,\n",
    "            max_restarts_iterations_without_improve= max_restarts_iterations_without_improve\n",
    "        )\n",
    "\n",
    "        (\n",
    "            clique,\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ) = runner.meta_heuristic()\n",
    "        assert check_validity_for_adjacency(graph, clique)\n",
    "        # Adding to display\n",
    "        new_row = [\n",
    "            instance,\n",
    "            name,\n",
    "            np.sum(starting_clique),\n",
    "            np.sum(clique),\n",
    "            ALL_BEST_KNOWN[instance],\n",
    "            \"{:.1%}\".format(1 - np.sum(clique) / ALL_BEST_KNOWN[instance]),\n",
    "            \"{:.1%}\".format(\n",
    "                np.sum(np.where(starting_clique == clique, 0, 1)) / number_of_nodes\n",
    "            ),\n",
    "            time_best_found,\n",
    "            iteration_of_best,\n",
    "            number_of_iterations,\n",
    "        ]\n",
    "        display_dataframe.loc[len(display_dataframe)] = new_row\n",
    "\n",
    "display_dataframe.to_csv(f\"vns_comparison_{max_time}_base_instances.csv\", sep=\";\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('projet_MH': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014c32241fd24097c2ed30b986768831995353224364fca8d9b563f6fce9ba3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
